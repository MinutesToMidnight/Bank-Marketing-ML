from torch import tensor, float32, long
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from DataLoader import DataLoader
from Visualizer import Visualizer
from MLModel import ModelUse

if __name__ == "__main__":
    path_to_file = "D:/Python/Python Projects/PycharmProjects/bank-full.csv"
    DL = DataLoader(path_to_file)
    df = DL.load_data()
    d = DL.count_missing(df)
    for col in d:
        print(f"{col}: {d[col]}")
    print()
    categorial_columns = ["job", "marital", "education", "contact", "month", "poutcome"]
    binary_columns = ["default", "housing", "loan", "y"]
    numeric_columns = list(set(df.columns) - set(categorial_columns) - set(binary_columns))
    X, y, preprocessor = DL.preprocess(df, numeric_columns=numeric_columns,
                                       binary_columns=binary_columns,
                                       categorial_columns=categorial_columns,
                                       keywords_for_binary={col: {"yes": 1, "no": 0} for col in binary_columns},
                                       target_column=df.columns[-1],
                                       target_type="binary")
    visualize = Visualizer()
    graph_funcs = visualize.get_graphs()
    for method in graph_funcs:
        method(df, numeric_columns)
    print()
    X, y = tensor(X, dtype=float32), tensor(y, dtype=long)
    model = nn.Sequential(nn.Linear(X.size(1), len(set(y))))
    trigger = ModelUse(model=model, optimizer=optim.Adam(model.parameters(), lr=0.01), criterion=nn.CrossEntropyLoss())
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42, stratify=y)
    trigger.train(X_train, y_train, epochs=3)
    trigger.evaluate(X_test, y_test)
